# Background

I try to maintain a blog but it requires a long time to write high quality interesting posts. So this space should work as a less formal dump for things I'm intereted in lately. I'll try to keep this as updated as possible.

# Learnability:

What can neural architectures (efficiently/practically/robustly/optimally) learn? What does using formal language learning (what is a good downstream task to see if a model has "learnt" a language? classification? prediction? something else?) as a sandbox tell us about inductive biases of modern neural nets?

1. \[1\] [Why are Sensitive Functions Hard for Transformers?](https://arxiv.org/pdf/2402.09963) _Hahn et. al._
2. \[2\] [The Expressive Capacity of State Space Models: A Formal Language Perspective](https://arxiv.org/pdf/2405.17394)
3. \[3\] 